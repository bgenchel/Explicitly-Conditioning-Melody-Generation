{
    "num_layers": 2,
    "seq_len": 16,
    "dropout": 0.0,
    "batch_norm": true,
    "output_dim": 128,
    "batch_size": 64,
    "embedding_dim": 32,
    "hidden_dim": 128,
    "input_dict_size": 128,
    "no_cuda": false
}